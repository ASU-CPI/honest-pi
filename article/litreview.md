#Literature Review
version 0.2.0

- examples, observations of the phenomenon
- what is open governance?
- evidence-based deliberative democracy (e.g., Habermas)
- agonistic pluralism (e.g., [Mouffe](http://www.jstor.org/discover/10.2307/40971349?uid=3739552&uid=2&uid=4&uid=3739256&sid=21103788623627)
- 


###Some Text from the original blog post:

Starting first with "[Scientists’ depressing new discovery about the brain](http://www.salon.com/2013/09/17/the_most_depressing_discovery_about_the_brain_ever_partner/)" (Marty Kaplan writing in Salon), which is really a shorter form of "[Science confirms: Politics wrecks your ability to do math](http://grist.org/politics/science-confirms-politics-wrecks-your-ability-to-do-math/)" (Chris Mooney, Grist), both are essentially reporting on recent research that shows that highly numerate people with strong political convictions fail a mathematical challenge when the correct answer to the math problem contradicted their political beliefs. This finding was even more likely when the subject was good at math and when their political beliefs were strongly entrenched.

Before going much further, we should probably look at the original research that’s in a draft working paper called "[Motivated Numeracy and Enlightened Self-Government](http://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2319992)" (Dan Kahan, Ellen Peters, Erica Cantrell Dawson and Paul Slovic, who hold affiliations with Yale, Harvard, Ohio State, Oregon, and Cornell - reasonably reputable institutions). This paper compares two explanations for how people’s beliefs can deviate from the evidence: the “Science Comprehension Thesis” (SCT), where persistent controversy over policy-relevant facts are attributed to deficits in the public’s capacity to understand scientific evidence; and the “Identity-protective Cognition Thesis” (ICT), where the public’s capacity to interpret decision-relevant science is disabled by cultural and political conflict. Political "polarization did not abate among subjects highest in Numeracy; instead, it increased. This outcome supported ICT, which predicted that more Numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlook.” In short, believing causes seeing.

(It’s interesting to note that Kahan et al. have become embroiled in [political controversy](http://news.sciencemag.org/brain-behavior/2013/10/statistical-fluke-researchers-observations-tea-party-and-science-spark) over the controversial politics of their findings. It seems that people tend to support their findings when they agree with them, and otherwise pillory them when the results are less than complementary).

This latest round of “do evidence and facts even matter?” supports several existing theories that have important implications for environmental communication, policy and collaborative governance. The theory of cultural cognition suggests people form risk perceptions “that reflect and reinforce values that they share with others” (Douglas & Wildavsky, 1982 in [Risk and culture: An essay on the selection of technical and environmental dangers][5]). Confirmation bias suggests that strongly held perceptions,whether driven by culture, cognition or political affiliation, will prevent individuals from changing their beliefs when presented with information that conflicts with their existing beliefs. “Blowin’ in the Wind: Short-Term Weather and Belief in Anthropogenic Climate Change” ([Hamilton and Stampone, 2013][6]) measured climate change beliefs, political affiliation and daily temperatures in New Hampshire and found that temperature fluctuations and anomalies influenced independent beliefs about climate change while Democrats and Republicans remained “far apart and ﬁrm in their beliefs about climate change.” In “[When corrections fail: The persistence of political misperceptions][7]” (Brendan Nyhan and Jason Reifler, in Political Behavior \- also available in draft form [here][8]), the idea of a “backfire effect” is proposed: “individuals who receive unwelcome information may not simply resist challenges to their views. Instead, they may come to support their original opinion even more strongly.” Even more alarming than the finding that evidence doesn't convince people of something - it turns out that more facts can actually entrench people's opposite beliefs, making them hold on more strongly to what they believe. The idea of a “backfire effect” from too much evidence was popularized in several places, notably “[Researchers discover a surprising threat to democracy: our brains][9]” (Joe Keohane writing in the Boston Globe) and by David McRaney on his blog “[You are not so smart: a celebration of self-delusion][10].”

It is possible that what's really being observed is that highly numerate people didn't so much as get the math wrong as their numeracy and their perspective caused them to view the data sceptically. But even this is explained in the research literature: In “[Motivated Skepticism: Use of Differential Decision Criteria for Preferred and Nonpreferred Conclusions][11]”, Peter Ditto and David Lopez show that “information consistent with a preferred conclusion is examined less critically than information inconsistent with a preferred conclusion” and this appears to be extremely important for individuals with greater scientific numeracy. In a previous study ([Kahan et al. 2011][12]), it was reported that the “cultural polarization” effect was more distinct among highly literate individuals: “respondents predisposed by their values to dismiss climate change evidence became more dismissive, and those predisposed by their values to credit such evidence more concerned, as science literacy and numeracy increased.”

These findings - the tendency to interpret evidence in a way that suits our beliefs, to have our beliefs reinforced by evidence that supports those beliefs and the inability of contrary evidence to persuade us otherwise - would seem to lie at the root of group polarization. As Cass Sunstein wrote recently on his interpretation of the October 2013 government shutdown, when like-minded people speak only to each other - if I only trust Fox News and you only trust MSNBC - they tend to become more extreme, more confident and more unified (Sunstein also wrote about the way the Internet could fuel such “echo chambers” in his 2009 book [Republic.com 2.0][13]). When this happens broadly in society, we lament the absence of civil discourse, reasoned debate and social capital. When it happens amongst our legislators - which we lament more, since we had hoped that as professional fact-checkers they might find more things they agree on, not less - we get stalemate. There is a persuasive argument put forward by proponents of agonistic pluralism (see Chantal Mouffe “[Deliberative Democracy or Agonistic Pluralism][14]”) that the ideal of deliberative democracy is perhaps a little too idealistic, that democracy involves an “ineradicability of antagonism and the impossibility of achieving a fully inclusive rational consensus,” and that we should stop striving for it. Well … that was easy.

There appear to be many public policy issues where there is fairly strong empirical evidence, yet we still have intense public debate not just about the choices to be made in the face of a looming problem, but about the very nature of the problem - or even whether a problem exists. Anthropogenic global warming is perhaps the most prominent issue, but such issues can be found in policy areas such as public health, public safety, fiscal and monetary policy and environmental risk. On global warming, there are some who look at the [Fifth Assessment Report of the Intergovernmental Panel on Climate Change][15] as the point at which the climate “debate” can finally be settled, where every reasonable person will now agree that human activity has played a significant role in recent climate change and that [we must act now][16]. Others who see the issue differently immediately pointed to the [absence of observed warming ][17]and [past over-predictions][18] as proof that the science can not yet been declared definitive.

   [5]: http://www.amazon.com/Risk-Culture-Selection-Technological-Environmental/dp/0520050630
   [6]: http://journals.ametsoc.org/doi/abs/10.1175/WCAS-D-12-00048.1
   [7]: http://link.springer.com/article/10.1007/s11109-010-9112-2
   [8]: http://www.dartmouth.edu/~nyhan/nyhan-reifler.pdf
   [9]: http://www.boston.com/bostonglobe/ideas/articles/2010/07/11/how_facts_backfire
   [10]: http://youarenotsosmart.com/2011/06/10/the-backfire-effect/
   [11]: https://webfiles.uci.edu/phditto/peterditto/Publications/Ditto%20%26%20Lopez%201992.pdf?uniq=-5wjp5m
   [12]: http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1871503
   [13]: http://press.princeton.edu/titles/8468.html
   [14]: http://www.ihs.ac.at/publications/pol/pw_72.pdf
   [15]: http://www.ipcc.ch/
   [16]: http://www.huffingtonpost.ca/david-suzuki/ipcc-report-climate-change_b_4026114.html?utm_hp_ref=tw
   [17]: http://www.dailytech.com/After%2BMissing%2B5%2BPredictions%2BIPCC%2BCuts%2BGlobal%2BWarming%2BForecast/article33457.htm
   [18]: http://www.nature.com/nclimate/journal/v3/n9/full/nclimate1972.html
