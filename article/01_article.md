version 0.5.1

June 3 2014, 5 pm MST-AZ

This is the MASTER VERSION of the document compiled at milestones throughout the project. 

N.B.: MASTER VERSION has been decompiled for now. Please see the component parts linked to below.

___
[## Title: What's an honest policy informatician to do?](https://github.com/ASU-CPI/honest-pi/blob/master/article/0a_title.md)

#Evidence-based decision making and decision-based evidence making: What's an honest policy informatician to do?
version 0.1.0

see [wiki page](https://github.com/ASU-CPI/honest-pi/wiki/Article-Title) for discussion of possible title ideas.

___
[### Authors: To be determined](https://github.com/ASU-CPI/honest-pi/blob/master/article/0b_authors.md)

#Authors
version 0.1.0 

Subject to discussion amongst contributors 

See [rules](https://github.com/ASU-CPI/honest-pi/blob/master/rules.md)

One way to do determine either authors or contributors could be to allow contributors to complete a taxonomy for each contributor. The taxonomy can be found here: http://www.nature.com/news/publishing-credit-where-credit-is-due-1.15033?WT.ec_id=NATURE-20140417. 

___
[### Abstract:](https://github.com/ASU-CPI/honest-pi/blob/master/article/0c_abstract.md)

#Abstract
version 1.0.0

Policy informatics is an emerging discipline built on the idea that complex public policy challenges are best addressed through the leveraging of computation and communication technologies that improve data collection, enhance analysis, harness knowledge in support of decision making, facilitate informed deliberation and provide mechanisms for rational collective action. At the core of the policy informatics movement are several premises, including that the objective of evidence-based analysis should be to better inform deliberation and decision making, and that better-informed decisions are preferred to less-informed decisions. Recent research and experience seems to indicate, however, that basic analytical functions are influenced by one's beliefs, that evidence is often selectively used to support one's argument, and that "facts" supporting a contrary position rarely succeed in changing one's beliefs, position or decision. If these findings are true, they would seem to undermine the founding principles of policy informatics, or at least question teh relevance of policy informatics in political debate and decision making. We review the explanations of the current state of evidence-based deliberation and policy making and propose a recalibration of the objectives for policy informatics that better reflect the political and psychological underpinnings of decision making. 

___
[### Keywords:](https://github.com/ASU-CPI/honest-pi/blob/master/article/0d_keywords.md) 

#Keywords
version 0.1.2

- policy informatics
- public policy
- open governance
- beliefs
- processes
- comprehension
- cognition
- empricism
- politics
- identity

___
[## Introduction](https://github.com/ASU-CPI/honest-pi/blob/master/article/1.0_introduction.md)

#Introduction
version 1.2.1

The policy sciences emerged around the middle of the past century, built on the idea that social problems were amenable to scientifically informed, rationally derived, government led solutions that could be free of the ambiguities and paradoxes of politics (Lasswell, 1951). A mark of pride of the modern, rational, professionally goverened state (Simon, 1976) was that objective advice based on evidence, analysis and expertise could usefully inform a decision maker’s thinking, and that “good” policy analysis was a key foundation for “good” policy decisions (Quade, 1975). Like the related fields of political science, public administration, law and economics, the public policy aims of these social sciences share a common mission: to inform public policy deliberation using analysis of evidence based on scientific methods, presented as rational argumentation (Stone, 2012). 

Policy informatics is an emerging discipline that draws upon this rationalist policy sciences traditional and combines it with system sciences (von Bertalanffy, 1968; Weiner, 1948) in an interdisciplinary exploration of how advances in information and communications technologies (ICTs) can strengthen and broaden the policy sciences approach, improving decision support while increasing the range of voices accommodated within the discussion. Policy informatics is not a technocratic or purely computational approach to policy analysis (at least not in the way we define it here); the use of ICTs as facilitators of deliberation and collaboration are as much part of the policy informatics approach as are the use of ICT-based techniques such as agent-based modelling, big data analytics and simulation (Johnston and Kim, 2012). In this way, policy informatics accommodates the post-positivist turn in policy analysis (Fischer, 1998) while being grounded in Lasswell's vision of the policy sciences as a joining of scientific analysis with democratic studies (deLeon, 1997).

However, at the core of the policy sciences approach - and, by extension, policy informatics - are several premises, including that the objective of evidence-based analysis should be to better inform deliberation and decision making, that better-informed decisions are preferred to less-informed decisions and that objective facts are both attainable and a necessary foundation for rational discourse. Whether the application of ICTs is emphasized or not, both approaches - policy sciences and policy informatics - share a belief that more information is preferred to less, that rationality is preferred to irrationality, that evidence is preferred to belief and objective analysis can provide clarity in uncertain situations.

Our concern here is with what role policy informatics can play in an environment where those premises appear not to be valid. What if the core assumptions underlying policy informatics are untrue, because values and beliefs weigh so heavily on interpretation that they alter receptivity to information and ultimately guide decision-making?  

In the fall of 2013, we began to notice increasing Internet chatter highlighting research suggesting that a person’s ability to solve a mathematical problem is affected by their beliefs (see Kahan et al., 2012). In most instances 2 + 2 = 4. But if the answer 4 conflicts with your beliefs or preferences, an answer that aligned more closely to your beliefs will be more persuasive. And then, it gets worse: telling you that the answer is 4 - an answer at odds with your strongly held belief - may only cause you to more strongly hold onto your insistence that the answer is actually 30. Or -5. Or the methods that produced 4 are suspect. Or that the premise of the question is flawed. 

While motives are always difficult to determine with certainty, we seperate here those who engage in wilful, strategic misrepresentation of evidence for purposes of agenda-setting, political advantage and goal attainment (Flyvbjerg, Holm and Buhl, 2002) from the deeper finding of cognitive psychology that reveal our tendency to see what we believe. 

Added to this specific finding are general observations about the state of deliberation and policy making in our democracies: debates about the very existence of human-caused climate change forestall debates about how to best address the problem; epidemiological and drug-trial evidence are questioned by activist parents who point towards possible government and drug company conspiracies as reasons to avoid common childhood vaccinations; whether Social Security is sustainable over the long-term, whether wealth inequality is increasing or gender pay-differences exist depends on which model you believe. 

Such deeply troubling findings and observations cause us to ask: how can we have rationale governance when we can’t rely on evidence to frame our discussions? Moreover, how can we hope to facilitate informed decisions and actions when ideological beliefs trump scientific facts? 

This article is an investigation of this challenge. 

(needs article overview)


[###What is Policy Informatics](https://github.com/ASU-CPI/honest-pi/blob/master/article/1.1_whatispi.md)

##What is Policy Informatics
version 1.0.0

Policy informatics centers on the study of how computational, information and communication technologies are leveraged to understand and address complex public policy and administration problems, and support new governance processes. It is built on the fundamental premise that technology can be efficiently and effectively mobilized in support of evidence-based policy analysis, design and implementation. Policy informatics advances the goal of building public governance that is transparent, collaborative, participatory and legitimate. 

Although an emerging discipline, three distinct research clusters are seen as developing: analysis; governance infrastructures; and processes. Analysis focuses on the assembling of data as the basis of evidence; visualizing information; and modeling complex policy environments. Governance research focuses on building the next-generation of public institutions; designing open, collaborative and participatory governance platforms; building participatory platforms to leverage collective intelligence; and promoting innovation in public institutions. Processes focuses on understanding how the adoption of technology changes the policy process; how technology affects administrative processes; and how technology-enabled networks support collaborative governance (Desouza and Johnston, forthcoming). 

___
[## Literature Review](https://github.com/ASU-CPI/honest-pi/blob/master/article/2_litreview.md)

#Literature Review
version 0.4.0

Section outline:
- what's the problem? examples, observations of the phenomenon
- special case of climate change "debate"
- streams of literature that explain the phenomenon

Science communication requires the important distinction that both facts and values are at play when citizens interpret scientific results as evidence or information (Dietz, 2013).  This is critical because as science has become more important to our society in recent decades, science has been increasingly politicized and therefore interpreted through a political framework based on values.  

##Opinions and Facts

Daniel Patrick Moynihan's assertion that "everyone is entitled to their own opinion but not their own facts" raises two interesting issues, centring on what constitutes an opinion and how do we define facts. Stokes (2012) refutes the claim that "everyone is entitled to their opinion" by describing three types of opinions (as between preferences, values and facts) and distinguishing between one's right to privately believe whatever they wish and the right to assert that belief in an argument. If an opinion is taken as a matter of taste (let's call these type 1 opinions) - e.g., to prefer tea to coffee - it is unreasonable to argue about a difference of opinion. However, opinions can also cover views that concern most people, as in the best course of action given plausible alternatives (type 2 opinions). These are a reasonable and traditional bases for argument, lying at the heart of many public policy choices. Where uncertainty about outcomes or implications remain, differences of opinion are likely to persist. (The distinction between opinions taste and opinions as to social choices perhaps explains why debates about public art are usual contentious, as they conflate two types of opinion).

A third type of opinion centers on judgement based on technical expertise, clear methods and evidence, and can range from legal to scientific (type 3 opinions). It is this realm, where "opinion" means much more than preference or choice amongst equally plausible alternatives. While reasonable experts can still have differences of opinion (recalling the old saw about asking three economists for their judgement, and getting four opinions), the accepted rules, procedures and methods for arbitrating amongst differences of opinion allow for the emergence of a (tentatively) accepted concensus. 

What has changed in recent years is the conflating of these opinions, and a breakdown in the accepted rules for engaging in debate around the third type of opinion. 

On the conflating of opinions based on preferences, values and evidence, one can have a preference for a certain outcome and are "entitled to their opinion". One can also have a world view or value set that inclines them to choose one option over another, whereas another person might select the alternative option. This would appear to the basis of Moynihan's assertion that "everyone is entitled to their own opinion". But it does not follow that a person has a right to an opinion about which there is a basis for rendering a opinion that can be based on expertise, methods of analysis and evidence. As Stokes (2012, n.p.) argues, "you are not entitled to your opinion. You are only entitled to what you can argue for.” It is in this realm that the right to have one's opinion taken into account in arriving at a consensus view rests on some evaluation of their credentials, expertise or methods.

Is that evaluation objective? Stokes (2012) makes a provocative distinction, that it is possible to be clear about who possesses relevant expertise in addressing "the science itself", but not about "policy responses to that science".  This claim puts the role of the honest policy informatician in a new light.  It also calls for some thought as to possible distinctions between possessing the relevant expertise to participate in deliberations, and generating relevant evidence to support deliberation and evidence-informed decisions.

To approach this question it might be useful to consider how expertise is evaluated in various fields.

- In mathematics, there are clear-cut standards to determine who might be recognized to have expertise in the ‘truth’ about the validity of reasoning from stipulated axioms through proofs to conclusion (although the success of crowdsourcing proofs to some difficult propositions [e.g., Gowers, 2009] might suggest the need for criteria going beyond conventional certification of credentials; it has long been recognized that mathematics shares much with music in matters of creativity and aesthetics).

- In law we have established canons on reasoning and proof, although not without controversy and with growing recognition of the importance of ‘performance practice’ in interpreting the intent of text through legal process, as well as a degree of subjectivity in judging the continued relevance and interpretation of legislation and codes in a changing social and cultural context.

- In accounting, ‘relevant expertise’ is clear in certification of understanding of Generally Accepted Accounting Principles and the application of those conventions in varying circumstances, although the question whether the same principles are appropriate to all organizational forms remains open.

Beyond these understandings of ‘relevant expertise’ as mastery of accepted conventions in which recognized or certified experts can dispute through well-defined institutional or social channels, we can question the nature of the criteria by which one reaches ‘truth’ or ‘facts’ that go beyond opinion, through science, or application of scientific method.  In principle, one can move from speculation to conjecture or hypothesis through received procedure meeting agreed standards (testability, replicability, etc.) to recognized and settled ‘facts’.  But of course the whole history of science is one of continued testing and frequent rejection of what seemed settled, and Thomas Kuhn has shown us that from time to time there are fundamental upheavals—paradigm shifts—that transform what have served for a long time as settled fact into yesterday’s illusions.

The question is, as it is increasingly recognized that there may be many forms of knowledge (or ‘knowledges’) through which we perceive and interpret the ‘facts’ that we wish to interpret as evidence in support of deliberation and decision, can we readily recognize what is ‘relevant expertise’?  More importantly for the present discussion, can we identify what is expertise relevant to deliberation around appropriate analysis of policy choices flowing from (agreed or contested?) interpretation of scientific findings for purposes of decision and policy formation leading to implementation and action?

How should the honest policy informatician support policy formation, or deliberation leading to policy formation?  More particularly, should web-based platforms or web-enabled exchange be designed to ensure that interaction is based on possession of relevant expertise, that deliberation processes gradually close in on the smaller community possessing expertise relevant to appraisal of policy options? Are we forced back to the view that it is only a matter of opinion how settled the current ‘facts’ are, as determined by the current degree of agreement around the relevant conventions?

It is possible that much of the disagreement over what is reasonably debatable in public policy issues (as in "there is no more climate debate") and what topics should only be subject to scientific methods by experts stems from a mischaracterization of choices based on values (opinion-types 1 and 2) and interpretations based on methods, expertise and evidence. Though much of the rhetoric from those opposing action has been aimed at discrediting the scientific opinions as to the existence, causes and consequences of cnthropogenic global warming, what seems more likely is that someone who is opposed to action on climate change has a worldview and value map that favours continued use of fossil fuels. (Though to what extent that worldview influences how they interpret the evidence is a lively topic in the philosophy of science). Presumably, as to preferences, most reasonable people would prefer a stable climate to an unstable one. So where differences of opinion matter is to whether we do nothing to constrain the growth of greenhouse gas emissions and deal with the possible consequences, or seek to avoid the possibility of catastrophic consequences by taking action. 

It should be evidenct that the categories or types of opinions - between preferences, values and judgement - lie along a spectrum rather than exist as clearly defined types. (This spectrum resembles the normative/positive distinction in, e.g., economics; Weston, 1994). Recent experience has seen the intrusion of normative argumentation into the types of positive opinions that used to be reserved exclusively for "scientists", bringing the rhetoric of politics along with it. Whether we like it or not, it appears more true now than ever that "everyone *is* entitled to their own opinion". This is what appears so unsettling to those who feel under continuing pressure to "debate" what they feel are settled scientific questions. (Another phenomenon is the unintended consequences of the reification of "evidence-based decision making", which has given an incentive to those who used to constrain themselves to the second type of opinion to proactively enter the arena of the third type to discredit the evidence-based opinions before they are able to infiltrate and influence the second type.) 

So much for the first half of Moynihan's conjecture; what of not being entitled "to their own facts". Underlying the disputability of "facts" - or the ability to insert one's own facts into a discussion as an alternative to other facts - is the issue of epistemic or factual relativism, in which "What one generally calls a fact is an interpretation of a situation that no one, at least for the moment, wants to call into question." (Gérard Fourez, quoted in Sokal and Bricmont, 1999, 101). Epistemic relativism also identifies the non-cognitive interests or unconcious influencers (economic or social incentives, risk perceptions, values) that determine not just the acceptance of scienctific findings, but the course of science itself. Plato distinguished between opinion or common belief (doxa) and certain knowledge, and his purpose was to argue that reason is superior to opinion or intuition, a belief that stays with us (Saul, 1997). While reason has its limits, only an extreme position of factual relativism would argue that objective truth does not exist. However, post-positivism does mean that the priests of knowledge are losing their power; as the Internet democratizes knowledge, taking it out of the exclusive hands of experts, "non-experts" can no longer be excluded from policy debates which rely upon science arguments. 

Relativism as a philosophy of science holds that science does not represent a superior or reliable way of knowing. Laudan (1990) critiques relativism, especially the claim that all science is value-driven and thus all facts are socially constructed. 



Of course the fact/value distinction has been subject to considerable discussion and interpretation in itself.  It may be important to consider beliefs as an intervening variable between hard facts and values as norms of conduct.  Pre-existing beliefs and world views may strongly influence the interpretation of the evidence offered by factual scientific material, as noted briefly below. 

The challenge: When the science is "uncertain" and when the "facts" are unclear, you cannot have a productive discussion about governance objectives and associated collective policy or consequential individual action. Uncertain science requires us to focus on a more nuanced view of public deliberation as contested and conflicted political activity rather than an orderly translation of governance or management objectives into rational and coherent action.

- challenges with evidence-based deliberative democracy (e.g., [Dahlberg](http://onlinelibrary.wiley.com.ezproxy1.lib.asu.edu/doi/10.1111/j.1083-6101.2001.tb00137.x/full))
- agonistic pluralism (e.g., [Mouffe](http://www.jstor.org/discover/10.2307/40971349?uid=3739552&uid=2&uid=4&uid=3739256&sid=21103788623627)) 
- [Bringing values and deliberation to science communication](http://www.pnas.org/content/110/Supplement_3/14081.full) - Tom Dietz 
- See recent issue in PAR on values http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1540-6210/earlyview
- [No, you’re not entitled to your opinion](http://theconversation.com/no-youre-not-entitled-to-your-opinion-9978#comment_88159) - Patrick Stokes
- policy analysis literature: intersection of analysis and politics; post-positivism, "evidence, argument and persuasion" (Majone), "democracy and expertise" (Fischer); 




###Climate Change, as an example


There appear to be many public policy issues where there is fairly strong empirical evidence, yet we still have intense public debate not just about the choices to be made in the face of a looming problem, but about the very nature of the problem - or even whether a problem exists. Anthropogenic global warming is perhaps the most prominent issue, but such issues can be found in policy areas such as public health, public safety, fiscal and monetary policy and environmental risk. On global warming, there are some who look at the [Fifth Assessment Report of the Intergovernmental Panel on Climate Change](http://www.ipcc.ch/) as the point at which the climate “debate” can finally be settled, where every reasonable person will now agree that human activity has played a significant role in recent climate change and that [we must act now](http://www.huffingtonpost.ca/david-suzuki/ipcc-report-climate-change_b_4026114.html?utm_hp_ref=tw). Others who see the issue differently immediately pointed to the [absence of observed warming](http://www.dailytech.com/After%2BMissing%2B5%2BPredictions%2BIPCC%2BCuts%2BGlobal%2BWarming%2BForecast/article33457.htm) and [past over-predictions](http://www.nature.com/nclimate/journal/v3/n9/full/nclimate1972.html) as proof that the science can not yet be declared definitive.


Is this about observed changes in climate and believing they are/are not occurring, the role of human activities in driving such change, CO2 emissions specifically, the impacts climate change (regardless of the relative contributions of various causes) will have on society?)

- Beliefs about climate change and importance as a policy issue: [Climate Change: Key Data Points from Pew Research](http://www.pewresearch.org/key-data-points/climate-change-key-data-points-from-pew-research/)
- one web resource out of many that take a "just the facts" approach: ["American Association for the Advancement of Science (AAAS): What We Know - The Reality, Risks and Response to Climate Change."](http://whatweknow.aaas.org/wp-content/uploads/2014/03/AAAS-What-We-Know.pdf)
- ["Americans' views", by Monica Contestabile, Nature Climate Change 4, 86 (2014) doi:10.1038/nclimate2109](http://www.nature.com/nclimate/journal/v4/n2/full/nclimate2109.html)
- ["Psychology: Local weather and climate concern", by Patrick J. Egan & Megan Mullin, Nature Climate Change 4, 89–90 (2014) doi:10.1038/nclimate2104](http://www.nature.com/nclimate/journal/v4/n2/full/nclimate2104.html)
- [Nature Climate Change - Focus: Public and experts' views about climate change](http://www.nature.com/nclimate/focus/views-about-change/index.html): Individuals' perceptions of, and beliefs about, climate change are affected by direct experience as well as the social, cultural and political context. Communication of a significant degree of scientific agreement on anthropogenic global warming can reduce biases in the formation of people's opinions, but the degree of consensus needs to be quantified. In this web focus, we present a collection of original research and opinion pieces that highlight the various dimensions of public and experts' interpretations of climate change.
- ["How warm days increase belief in global warming", by Lisa Zaval, Elizabeth A. Keenan, Eric J. Johnson & Elke U. Weber, Nature Climate Change 4, 143–147 (2014) doi:10.1038/nclimate2093](http://www.nature.com.ezproxy1.lib.asu.edu/nclimate/journal/v4/n2/full/nclimate2093.html)
- [Political Rifts Slow U.S. Effort on Climate Laws](http://www.nytimes.com/2014/04/15/us/politics/political-rifts-slow-us-effort-on-climate-laws.html?smid=tw-share&_r=0)
- [Why climate deniers are winning: The twisted psychology that overwhelms scientific consensus](http://www.salon.com/2014/04/19/why_climate_deniers_are_winning_the_twisted_psychology_that_overwhelms_scientific_consensus/)

It is important, in this example, to consider explicitly the possible need to respond to wilful or strategic misrepresentation.  One specific example is illustrated in the discussion stemming from a recent Wall Street Journal op-ed piece, as set out in the chain:
http://skepticalscience.com/wsj-denies-global-warming-consensus.html

http://www.theguardian.com/environment/climate-consensus-97-per-cent/2013/oct/04/global-warming-debate-not-about-science 

http://www.theguardian.com/environment/planet-oz/2013/oct/02/climate-change-denial-skeptics-psychology-study-conspiracy-theories 

http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0075637

http://thinkprogress.org/climate/2014/05/22/3440827/mckinley-climate-pentagon-climate-change/

It is hard to believe that the WSJ, in agreeing to publish the editorial in question, or the Heartland Institute authors involved, truly believe the views explicitly put forward as factual.  But they might perhaps feel that their misrepresentation can be justified on the classic grounds of the 'Noble Lie', or the lie in the public interest, believing as they do that the policies that might flow, and the instruments that might be adopted, to address the risks posed by AGM entail unacceptable  consequences for the public far beyond those associated with counter-factual denial of those risks.  Their underlying altruistic motives may be seen as warranting the rejection of any consensus around the interpretation of the evidence.  (The classic work dealing with the implications of such claims is Lying, by Sissela Bok (Bok, 1978.)

Outside of such extreme cases, there is substantial evidence accumulating on the way in which beliefs, world views, social and cultural context, and emotions unintentionally colour the reasoning processes through which we interpret evidence.

Kahan et al.: why doesn't evidence-based analysis resolve political debates? Testing the "Science Comprehension Thesis" (the public is not capable of understanding the science) points towards more education as the solution. The alternative hypothesis centers not on finding the right answer but on prevailing in arguments, increasing or maintaining standing, or group affinity. Perhaps humans reason for purposes other than finding the truth — purposes like increasing their standing in their community, or ensuring they don’t piss off the leaders of their tribe; in this model, more education doesn't settle arguments - it makes participants better able to argue for their side and dismiss the opposing arguments.

The findings show generally that for issues where respondents would not have a preference over the result (e.g., efficacy of a skin cream), the Science Comprehension Thesis fits: more education (specifically in mathematical reasoning) improved a respondents ability to correctly interpret evidence. When presented with a topic having political overtones (e.g., the efficacy of gun control laws on crime statistics), strong mathematical reasoning abilities no longer predicted ability to correctly solve the problem; rather, the ideology of the respondent became the dominant factor in ability to correctly reason based on the evidence.

Starting first with "[Scientists’ depressing new discovery about the brain](http://www.salon.com/2013/09/17/the_most_depressing_discovery_about_the_brain_ever_partner/)" (Marty Kaplan writing in Salon), which is really a shorter form of "[Science confirms: Politics wrecks your ability to do math](http://grist.org/politics/science-confirms-politics-wrecks-your-ability-to-do-math/)" (Chris Mooney, Grist), both are essentially reporting on recent research that shows that highly numerate people with strong political convictions fail a mathematical challenge when the correct answer to the math problem contradicted their political beliefs. This finding was even more likely when the subject was good at math and when their political beliefs were strongly entrenched.

Before going much further, we should probably look at the original research that’s in a draft working paper called "[Motivated Numeracy and Enlightened Self-Government](http://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2319992)" (Dan Kahan, Ellen Peters, Erica Cantrell Dawson and Paul Slovic, who hold affiliations with Yale, Harvard, Ohio State, Oregon, and Cornell - reasonably reputable institutions). This paper compares two explanations for how people’s beliefs can deviate from the evidence: the “Science Comprehension Thesis” (SCT), where persistent controversy over policy-relevant facts are attributed to deficits in the public’s capacity to understand scientific evidence; and the “Identity-protective Cognition Thesis” (ICT), where the public’s capacity to interpret decision-relevant science is disabled by cultural and political conflict. Political "polarization did not abate among subjects highest in Numeracy; instead, it increased. This outcome supported ICT, which predicted that more Numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlook.” In short, believing causes seeing.

(It’s interesting to note that Kahan et al. have become embroiled in [political controversy](http://news.sciencemag.org/brain-behavior/2013/10/statistical-fluke-researchers-observations-tea-party-and-science-spark) over the controversial politics of their findings. It seems that people tend to support their findings when they agree with them, and otherwise pillory them when the results are less than complementary).

This latest round of “do evidence and facts even matter?” supports several existing theories that have important implications for environmental communication, policy and collaborative governance. The theory of cultural cognition suggests people form risk perceptions “that reflect and reinforce values that they share with others” (Douglas & Wildavsky, 1982 in [Risk and culture: An essay on the selection of technical and environmental dangers](http://www.amazon.com/Risk-Culture-Selection-Technological-Environmental/dp/0520050630)). Confirmation bias suggests that strongly held perceptions,whether driven by culture, cognition or political affiliation, will prevent individuals from changing their beliefs when presented with information that conflicts with their existing beliefs. “Blowin’ in the Wind: Short-Term Weather and Belief in Anthropogenic Climate Change” ([Hamilton and Stampone, 2013](http://journals.ametsoc.org/doi/abs/10.1175/WCAS-D-12-00048.1)) measured climate change beliefs, political affiliation and daily temperatures in New Hampshire and found that temperature fluctuations and anomalies influenced independent beliefs about climate change while Democrats and Republicans remained “far apart and ﬁrm in their beliefs about climate change.” In “[When corrections fail: The persistence of political misperceptions](http://link.springer.com/article/10.1007/s11109-010-9112-2)” (Brendan Nyhan and Jason Reifler, in Political Behavior \ - also available in draft form [here](http://www.dartmouth.edu/~nyhan/nyhan-reifler.pdf)), the idea of a “backfire effect” is proposed: “individuals who receive unwelcome information may not simply resist challenges to their views. Instead, they may come to support their original opinion even more strongly.” Even more alarming than the finding that evidence doesn't convince people of something - it turns out that more facts can actually entrench people's opposite beliefs, making them hold on more strongly to what they believe. The idea of a “backfire effect” from too much evidence was popularized in several places, notably “[Researchers discover a surprising threat to democracy: our brains](http://www.boston.com/bostonglobe/ideas/articles/2010/07/11/how_facts_backfire)” (Joe Keohane writing in the Boston Globe) and by David McRaney on his blog “[You are not so smart: a celebration of self-delusion](http://youarenotsosmart.com/2011/06/10/the-backfire-effect/).”

It is possible that what's really being observed is that highly numerate people didn't so much as get the math wrong as their numeracy and their perspective caused them to view the data sceptically. But even this is explained in the research literature: In “[Motivated Skepticism: Use of Differential Decision Criteria for Preferred and Nonpreferred Conclusions](https://webfiles.uci.edu/phditto/peterditto/Publications/Ditto%20%26%20Lopez%201992.pdf?uniq=-5wjp5m)”, Peter Ditto and David Lopez show that “information consistent with a preferred conclusion is examined less critically than information inconsistent with a preferred conclusion” and this appears to be extremely important for individuals with greater scientific numeracy. In a previous study ([Kahan et al. 2011](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1871503)), it was reported that the “cultural polarization” effect was more distinct among highly literate individuals: “respondents predisposed by their values to dismiss climate change evidence became more dismissive, and those predisposed by their values to credit such evidence more concerned, as science literacy and numeracy increased.”

Of course, the existence of belief-bias and other defects in reasoning has been recognized for a long time.  The retrospective discussions in the recent book "New Approaches in Reasoning Research" (de Neys and Osman, 2014) offer a succinct review, as does the earlier article "In Two Minds: dual-process acounts of reasoning" (Evans, 2003).

<Insert by Dobell to follow>
All these findings - the tendency to interpret evidence in a way that suits our beliefs, to have our beliefs reinforced by evidence that supports those beliefs and the inability of contrary evidence to persuade us otherwise - would seem to lie at the root of group polarization. As Cass Sunstein wrote recently on his interpretation of the October 2013 government shutdown, when like-minded people speak only to each other - if I only trust Fox News and you only trust MSNBC - they tend to become more extreme, more confident and more unified (Sunstein also wrote about the way the Internet could fuel such “echo chambers” in his 2009 book [Republic.com 2.0](http://press.princeton.edu/titles/8468.html)). When this happens broadly in society, we lament the absence of civil discourse, reasoned debate and social capital. When it happens amongst our legislators - which we lament more, since we had hoped that as professional fact-checkers they might find more things they agree on, not less - we get stalemate. 

In light of all this, we are obviously far away from the simple view of an orderly and straightforward flow of scientific knowledge or evidence-based belief into rationally-founded policy.  

There is a persuasive argument put forward by proponents of agonistic pluralism (see Chantal Mouffe “[Deliberative Democracy or Agonistic Pluralism](http://www.ihs.ac.at/publications/pol/pw_72.pdf)”) that the ideal of deliberative democracy is perhaps a little too idealistic, that democracy involves an “ineradicability of antagonism and the impossibility of achieving a fully inclusive rational consensus,” and that we should stop striving for it.

It is perhaps here that the contribution of the honest policy-oriented informatician can lie, in the development of more effective web-based platforms for ongoing interaction and deliberation, as discussed briefly below.

___
[## Discussion](https://github.com/ASU-CPI/honest-pi/blob/master/article/3_discussion.md)

#Discussion
version 0.3.0
- how can we resolve the apparent disconnect?
- does open data offer a solution? see e.g., [How open climate data can improve community resilience against climate change](http://www.techrepublic.com/article/how-open-climate-data-can-improve-community-resilience-against-climate-change/) and [http://thehill.com/blogs/congress-blog/energy-environment/201219-white-house-climate-change-initiative-republicans-can](http://thehill.com/blogs/congress-blog/energy-environment/201219-white-house-climate-change-initiative-republicans-can)
- does the policy sciences literature provide a solution? of is what's happening now (i.e., the willful dismissing of evidence at odds with one's preferred course of action) something new?

### Potential addition to discussion section:

Looking at the influence of the human mind on data interpretation, it is possible to feel discouraged about the likelihood of achieving the aspirations of Open Government. However, to do so would be to discount the impact of continued reflection and evolving practice. There is immense potential in people becoming aware of their behaviors and inclinations. This means that with constructive framing, people can learn to approach data differently than they would have done so before.

note from Stone (2012): why a completely rational approach ("just the facts") misses the point of policy making:
- the rational policy sciences approach sees politics as a paradox because the messiness of politics clashes with the world view of the rationality project. While politics has a dark, self-interested side that produces conflict, politics is also the route by which passions lead to creative solutions.
- rationality prides itself on being above politics; but the lenses that rationality brings to analysis are the product themselves of political claims not universal truths (see also Lasswell's normative basis of the the policy sciences).
- the rational policy approach is dominated by economics, which sees human interactions in terms of market mechanisms - which describes a world very different from most human interactions and community forms.

### Some Text from the original blog post: 
Public policy analysis a generation ago was characterized by a belief that more evidence will lead to better decisions, that education is the foundation of rational behaviour, and that in a democracy we should begin with a discussion of the facts. There’s a quote attributed to the late Senator Daniel Patrick Moynihan - “Everyone is entitled to his own opinion, but not to his own facts” - that characterizes this period in the 1970s, a golden age of policy debate during which Senator Moynihan was a key player.

That era appears to be well over (if it ever really existed). But in its wake, we are left wondering what hope there is for fields like policy informatics that seek to inform public discourse to enhance collaborative governance? In an environment like this, what’s an honest policy informatician to do?

In this post-positivist era, we're suspecting that it is not "information is what changes us" (Stafford Beer, [Platform for Change](http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471948403.html), p. 243); rather information is what we believe it is. So what can change us and “facilitate informed and empowered deliberation and action” as our mission statement urges us to strive for?

While information can be transmitted in documents and videos and conversations, it will lack resonance and tangibility with the recipient in the absence of experience or feeling. This is partly addressed by what people like David Roberts argue for (“[The Futility of ‘Just the Facts’ Climate Science”](http://grist.org/climate-energy/the-futility-of-just-the-facts-climate-science/)) in the bringing together of science and politics, for scientists to bring their values together with their findings when they communicate their findings: “if scientists want the information they convey to be understood and absorbed [to have meaning for their audience], they will have to speak as humans speak, from within a cultural identity and a set of values, not hovering above such mortal concerns.”

If we assume that the aforementioned evidence is correct, that “individuals will reflect and reinforce values they share with others” and that conflict over public policy is fostered by fundamentally different cultural worldviews and values, we start to wonder how we can build shared experiences, influence mental models and promote cultural consensus that will enhance collaborative decision making.

In the Center for Policy Informatics, we explore the potential for technology, computer simulation and participatory modeling to change mental models, perspectives and ultimately behavior. We measure the influence of games and visualization on mental models and beliefs. As just one example, LinkIT ([LinkIT: A Ludic Elicitation Game for Eliciting Risk Perceptions](http://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.2012.01907.x/abstract), by Yan Cao and William L. McGill) is a game-like tool designed to elicit group understanding of the relations between risk factors.

___
[## Implications](https://github.com/ASU-CPI/honest-pi/blob/master/article/4_implications.md)

#Implications
version 0.3.0

- what are some strategies for re-invigorating deliberative democracy?
- is policy informatics relevant in this new environment? Does it continue without reference to the problem as though to say there is nothing that can be done about it?

### Some Text from the original blog post
Our work looks towards the generation of experience and empathy through mechanisms more closely related to policy informatics. CPI is currently investigating whether participatory simulation and collaborative decision making can generate [synthetic empathy](https://cpi.asu.edu/project/synthetic-empathy). Empathy is the act of imagining, understanding, and actively responding to the conditions and perspectives of another related to a particular situation. This project uses a computer mediated synthetic environment as a deliberation space for individual participants to explore the perspectives of others, arrive at consensus, and make decisions for sustainable outcomes under conditions of uncertainty.

Drawing on the observations in “[When Truth Is Personally Inconvenient, Attitudes Change: The Impact of Extreme Weather on Implicit Support for Green Politicians and Explicit Climate-Change Beliefs](http://pss.sagepub.com/content/early/2013/09/19/0956797613492775.abstract),” we see how our experiences can change what we believe. Joint experiences can promote shared mental models ([Robert et al. 2008](http://pss.sagepub.com/content/early/2013/09/19/0956797613492775.abstract)). Direct experience with extreme weather events increases a person’s support for politicians promoting environmental causes (see “[After the Storms, A Different Opinion on Climate Change](http://www.psychologicalscience.org/index.php/news/releases/after-the-storms-a-different-opinion-on-climate-change.html)”). We do not suggest creating hurricanes in order to change beliefs about climate change (the human research ethics challenges would be significant, for starters). But we can draw on the use of computation and communication technology as a means to simulate experience through immersive computer environments. Additional research is currently exploring whether the development of a participatory model can generate relational social capital, enhance reciprocity and knowledge exchange (e.g., Takahashi 2000, Yamagishi and Cook 1993; [Robert et al. 2008](http://pss.sagepub.com/content/early/2013/09/19/0956797613492775.abstract)).

If ideology can edge out opposing opinions, scientific facts, and influence basic math skills, information alone will not change us. Evidence-based decision making and public policy will also be influenced by shared norms, experiences and values. Our initial results suggest that computer-based simulations, participatory modeling and collaborative platforms, can be used to facilitate informed decisions and build collaboration. We hope that future research will contribute to continued improvements in our understanding of the complex processes that shape perspective-building and decision-making, ultimately leading to public policy and governance choices that lead to genuine societal improvements.

___
[## Challenges](https://github.com/ASU-CPI/honest-pi/blob/master/article/5_challenges.md)

#Challenges

version 0.1.0

___
[## Directions for Future Research](https://github.com/ASU-CPI/honest-pi/blob/master/article/6_future.md)

#Directions for Future Research
version 0.1.0

- what don't we know?
  Can we create subcategories here: 
  - Uncertainty
  - Conflict and Governance
  - Future societal needs that will require use of information and collaboration
  - etc. 
- what promising avenues need to be further investigated?
  - Technology and beliefs
  - Technology and collaboration
  - etc.
  - 
  


Text for addition in future societal needs

As we have discussed, societal problems continue to be relevant and complex. Understanding the dynamics between people and technology in decision making will become ever more relevant as time goes on. There are even larger global scale challenges that will require the premeditated collaboration of all governments and international organizations of the world. The upcoming Policy Challenge, a collaborative challenge hosted by the White House, provides a venue for participants to consider such upcoming challenges. One example is that of climate engineering. Another is the need for advanced space flight, particularly when paired with information about the high number of asteroids that currently hit Earth and the point that eventually one large enough to do severe damage will hit. 

Text for promising avenues for further investigation

A promising development in the advancement of decision making comes from our awareness of how our beliefs impact our interpretations and use of data. If people are aware of biases or preferences, it is possible to train on an individual and group level to look more critically at relevant information. Many of the authors of this article work at the Center for Policy Informatics, where the connection between decision making, technology, and complex problems are actively being studied. This work comes through the study of different structural configurations in online environments (Policy Challenge and 10,000 Solutions), the study of empathy in collaborative decision making, and theoretical explorations of collaborative governance. The Center of Policy Informatics is joined by other centers and individuals studying the connection of intentionality, technology, and the mind. (can include Uva, Chase Treisman [mindfulness], santa fe institute)

___
[## Conclusions](https://github.com/ASU-CPI/honest-pi/blob/master/article/7_conclusion.md)

#Conclusions
version 0.1.0
Summary of the paper
___
[## References](https://github.com/ASU-CPI/honest-pi/blob/master/article/8_references.md)

#References
version 0.1.3

Flyvbjerg, B., Holm, M. S., & Buhl, S. (2002). Underestimating costs in public works projects: Error or lie?. _Journal of the American Planning Association_, 68(3), 279-295.

Gowers, T. (27 January 2009). "Is massively collaborative mathematics possible?" _Gowers's Weblog: Mathematics related discussions_. http://gowers.wordpress.com/2009/01/27/is-massively-collaborative-mathematics-possible/

Kahan, D. M., Peters, E., Wittlin, M., Slovic, P., Ouellette, L. L., Braman, D., & Mandel, G. (2012). The polarizing impact of science literacy and numeracy on perceived climate change risks. _Nature Climate Change_, 2(10), 732-735.

Lasswell, H. D. (1951). “The policy orientation”, pp. 3-15 in D. Lerner and H.D. Lasswell (eds.), _The Policy Sciences_. Stanford, CA: Stanford University Press.

Laudan, L. (1990) _Science and Relativism: Some Key Controversies in the Philosophy of Science_. Chicago: University of Chicago,

Quade, E. S. (1975). _Analysis for public decisions_. New York: Elsevier.

Saul, J. R. (2013). _Voltaire's bastards: The dictatorship of reason in the West_. New York: Simon and Schuster.

Simon, H. A. (2013). _Administrative behavior_. 4th edition. New York: Simon and Schuster.

Sokal, A., & Bricmont, J. (1999). _Fashionable nonsense: Postmodern intellectuals' abuse of science_. Macmillan.

Stokes, P. (4 October 2012). "No, you’re not entitled to your opinion." _The Conversation_. http://theconversation.com/no-youre-not-entitled-to-your-opinion-9978

Stone, D. A. (2012). _Policy paradox: The art of political decision making_. 3rd edition. New York: W W Norton.

Weston, S. C. (1994). "Toward a better understanding of the positive/normative distinction in economics." _Economics and Philosophy_, 10, 1-1.
